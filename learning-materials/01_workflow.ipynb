{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffffff; color: #000000; padding: 10px;\">\n",
    "<div style=\"display: flex; justify-content: space-between; align-items: center; background-color: #ffffff; color: #000000; padding: 10px;\">\n",
    "    <img src=\"../images/logo_kisz.png\" height=\"80\" style=\"margin-right: auto;\" alt=\"Logo of the AI Service Center Berlin-Brandenburg.\">\n",
    "    <img src=\"../images/logo_bmbf.jpeg\" height=\"150\" style=\"margin-left: auto;\" alt=\"Logo of the German Federal Ministry of Education and Research: Gefördert vom Bundesministerium für Bildung und Forschung.\">\n",
    "</div>\n",
    "<h1> Efficient Information Retrieval from Documents\n",
    "<h2> Local Retrieval Augmented Generation System\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f6a800; color: #ffffff; padding: 10px;\">\n",
    "    <h2> Part 1 - Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #dd6108; color: #ffffff; padding: 10px;\">\n",
    "<h3>1. Basics - Handcrafted RAG</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Load Embedding model\n",
    "# https://www.sbert.net/\n",
    "# pip3 install sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Text\n",
    "\n",
    "texts = [\n",
    "    \"Bali's beautiful beaches and rich culture stands out as a fantastic travel destination.\",\n",
    "    \"Pizza in Rome is famous for its thin crust, fresh ingredients and wood-fired ovens.\",\n",
    "    \"Graphics processing units (GPU) have become an essential foundation for artificial intelligence.\",\n",
    "    \"Newton's laws of motion transformed our understanding of physics.\",\n",
    "    \"The French Revolution played a crucial role in shaping contemporary France.\",\n",
    "    \"Maintaining good health requires regular exercise, balanced diet and quality sleep.\",\n",
    "    \"Dali's surrealistic artworks, like 'The Persistence of Memory,' captivate audiences with their dreamlike imagery and imaginative brilliance\",\n",
    "    \"Global warming threatens the planet's ecosystems and wildlife.\",\n",
    "    \"The KI-Servicezentrum Berlin-Brandenburg offers services such as consulting, workshops, MOOCs and computer resources.\",\n",
    "    \"Django Reinhardt's jazz compositions are celebrated for their captivating melodies and innovative guitar work..\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings type: <class 'numpy.ndarray'>\n",
      "Embeddings Matrix shape: (10, 384)\n"
     ]
    }
   ],
   "source": [
    "# Encode texts\n",
    "\n",
    "text_embeddings = model.encode(texts)\n",
    "\n",
    "print(\"Embeddings type:\", type(text_embeddings))\n",
    "print(\"Embeddings Matrix shape:\", text_embeddings.shape)\n",
    "\n",
    "# Note: \"all-MiniLM-L6-v2\" encodes texts up to 256 words. It’ll truncate any text longer than this.\n",
    "# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### &bull; **Check Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing Embeddings in a simple dict\n",
    "\n",
    "text_embs_dict = dict(zip(texts, list(text_embeddings)))\n",
    "# key: text, value: numpy array with embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define similarity metric\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def cos_sim(x, y):\n",
    "    return dot(x, y) / (norm(x) * norm(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine similarities for: 'I really need some vacations'\n",
      "\n",
      "Bali's beautiful beaches and rich culture stands out as a fantastic travel destination. 0.302\n",
      "Pizza in Rome is famous for its thin crust, fresh ingredients and wood-fired ovens. 0.161\n",
      "Graphics processing units (GPU) have become an essential foundation for artificial intelligence. -0.089\n",
      "Newton's laws of motion transformed our understanding of physics. 0.022\n",
      "The French Revolution played a crucial role in shaping contemporary France. 0.012\n",
      "Maintaining good health requires regular exercise, balanced diet and quality sleep. 0.176\n",
      "Dali's surrealistic artworks, like 'The Persistence of Memory,' captivate audiences with their dreamlike imagery and imaginative brilliance 0.022\n",
      "Global warming threatens the planet's ecosystems and wildlife. 0.105\n",
      "The KI-Servicezentrum Berlin-Brandenburg offers services such as consulting, workshops, MOOCs and computer resources. 0.105\n",
      "Django Reinhardt's jazz compositions are celebrated for their captivating melodies and innovative guitar work.. 0.066\n"
     ]
    }
   ],
   "source": [
    "# Check similarities\n",
    "\n",
    "test_text = \"I really need some vacations\"\n",
    "emb_test_text = model.encode(test_text)\n",
    "\n",
    "print(f\"\\nCosine similarities for: '{test_text}'\\n\")\n",
    "for k, v in text_embs_dict.items():\n",
    "    print(k, round(cos_sim(emb_test_text, v), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **To do:**\n",
    "\n",
    "\n",
    "\n",
    " - Experiment with different sentences and compare similarities.\n",
    "\n",
    "\n",
    "\n",
    " - Check alternative sentence-transformers. Read Model Cards. Compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #dd6108; color: #ffffff; padding: 10px;\">\n",
    "<h3>2. Basics - A simple RAG tool</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "client = chromadb.Client()\n",
    "# client = chromadb.PersistentClient(path=\"chroma_data/\")\n",
    "# For a ChromaDB instance on the disk\n",
    "\n",
    "embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=EMBEDDING_MODEL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init collection\n",
    "\n",
    "COLLECTION_NAME = \"demo_docs\"\n",
    "\n",
    "collection = client.create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    embedding_function=embedding_func,\n",
    "    metadata={\"hnsw:space\": \"cosine\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collection\n",
    "# (Adding metadata. Optional)\n",
    "\n",
    "topics = [\n",
    "    \"travel\",\n",
    "    \"food\",\n",
    "    \"technology\",\n",
    "    \"science\",\n",
    "    \"history\",\n",
    "    \"health\",\n",
    "    \"painting\",\n",
    "    \"climate change\",\n",
    "    \"business\",\n",
    "    \"music\",\n",
    "]\n",
    "\n",
    "collection.add(\n",
    "    documents=texts,\n",
    "    ids=[f\"id{i}\" for i in range(len(texts))],\n",
    "    metadatas=[{\"topic\": topic} for topic in topics],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query dict keys:\n",
      "dict_keys(['ids', 'embeddings', 'documents', 'uris', 'included', 'data', 'metadatas', 'distances'])\n",
      "\n",
      "Query: I am looking for something to eat\n",
      "\n",
      "Results:\n",
      "id: id1\n",
      "Text: Pizza in Rome is famous for its thin crust, fresh ingredients and wood-fired ovens.\n",
      "Distance: 0.72\n",
      "Metadata: {'topic': 'food'}\n",
      "id: id5\n",
      "Text: Maintaining good health requires regular exercise, balanced diet and quality sleep.\n",
      "Distance: 0.85\n",
      "Metadata: {'topic': 'health'}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: What's going on in the world?\n",
      "\n",
      "Results:\n",
      "id: id7\n",
      "Text: Global warming threatens the planet's ecosystems and wildlife.\n",
      "Distance: 0.74\n",
      "Metadata: {'topic': 'climate change'}\n",
      "id: id3\n",
      "Text: Newton's laws of motion transformed our understanding of physics.\n",
      "Distance: 0.86\n",
      "Metadata: {'topic': 'science'}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: Great jazz player\n",
      "\n",
      "Results:\n",
      "id: id9\n",
      "Text: Django Reinhardt's jazz compositions are celebrated for their captivating melodies and innovative guitar work..\n",
      "Distance: 0.52\n",
      "Metadata: {'topic': 'music'}\n",
      "id: id4\n",
      "Text: The French Revolution played a crucial role in shaping contemporary France.\n",
      "Distance: 0.88\n",
      "Metadata: {'topic': 'history'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Quering the Database\n",
    "\n",
    "query1 = \"I am looking for something to eat\"\n",
    "query2 = \"What's going on in the world?\"\n",
    "query3 = \"Great jazz player\"\n",
    "\n",
    "queries = [query1, query2, query3]\n",
    "\n",
    "query_results = collection.query(\n",
    "    query_texts=queries,  # list of strings or just one element (string)\n",
    "    n_results=2,\n",
    ")\n",
    "print(\"Query dict keys:\")\n",
    "print(query_results.keys())\n",
    "\n",
    "for i in range(len(queries)):\n",
    "    print(\"\\nQuery:\", queries[i])\n",
    "\n",
    "    print(\"\\nResults:\")\n",
    "    for j in range(len(query_results[\"ids\"][i])):\n",
    "        print(\"id:\", query_results[\"ids\"][i][j])\n",
    "        print(\"Text:\", query_results[\"documents\"][i][j])\n",
    "        print(\"Distance:\", round(query_results[\"distances\"][i][j], 2))\n",
    "        print(\"Metadata:\", query_results[\"metadatas\"][i][j])\n",
    "\n",
    "    print(80 * \"-\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### &bull; **Running a Large Language Model locally with Ollama**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests, json\n",
    "from os import getenv\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# $ ollama serve\n",
    "BASEURL = urljoin(getenv(\"OLLAMA_HOST\", \"http://localhost:11434\"), \"api\")\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "\n",
    "def generate(prompt, context=[], top_k=5, top_p=0.9, temp=0.5):\n",
    "    url = BASEURL + \"/generate\"\n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model\": MODEL,\n",
    "        \"stream\": False,\n",
    "        \"context\": context,\n",
    "        \"options\": {\"temperature\": temp, \"top_p\": top_p, \"top_k\": top_k},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.post(url, json=data)\n",
    "        response_dic = json.loads(r.text)\n",
    "        return response_dic.get('response', ''), response_dic.get('context', '')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an artificial intelligence model designed to assist and communicate with users like you. I don't have a personal identity or emotions, but I'm here to provide information, answer questions, and engage in conversation to the best of my abilities.\n",
      "\n",
      "My purpose is to help users find the information they need, solve problems, and explore topics of interest. I'm constantly learning and improving my knowledge base, so please bear with me if I make any mistakes or don't have an answer to a specific question.\n",
      "\n",
      "How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm_response, _ = generate(\"Hi, who are you\", top_k=10, top_p=0.9, temp=0.5)\n",
    "print(llm_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### &bull; **Make a simple local LLM chatbot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with llama3.2 model (Press q to quit)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hi. who are you?\"\n",
    "ollama_context = []\n",
    "print(f\"Start chatting with {MODEL} model (Press q to quit)\\n\")\n",
    "while user_input != \"q\":\n",
    "    bot_response, ollama_context = generate(\n",
    "        user_input, context=ollama_context, top_k=10, top_p=0.9, temp=0.5\n",
    "    )\n",
    "    print(\"Model message:\")\n",
    "    print(bot_response)\n",
    "    user_input = input(\"\\nYour prompt: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **To do:**\n",
    "\n",
    "\n",
    "\n",
    " - Experiment with different input parameters, arguments, prompts and compare results.\n",
    "\n",
    " - Try different models (e.g. mistral, llama3.1, gemma2, qwen2.5, llama3.2, qwen2.5:3b, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -----------------------------------------------------------------------------\n",
    "\n",
    " ## Integration\n",
    "\n",
    " #### **Integrate the components for a RAG System.**\n",
    "\n",
    " ### References:\n",
    "\n",
    " #### &bull; **Text embedding: Sentence Bert**\n",
    "\n",
    " https://www.sbert.net/\n",
    "\n",
    "\n",
    "\n",
    " Sample Sentence Transformers:\n",
    "\n",
    "\n",
    "\n",
    " https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "\n",
    "\n",
    " https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1\n",
    "\n",
    "\n",
    "\n",
    " https://huggingface.co/sentence-transformers/multi-qa-mpnet-base-cos-v1\n",
    "\n",
    "\n",
    "\n",
    " Check and compare\n",
    "\n",
    " #### &bull; **Vector Database: ChromaDB**\n",
    "\n",
    " https://docs.trychroma.com/\n",
    "\n",
    " #### &bull; **Local LLM: ollama**\n",
    "\n",
    " https://ollama.ai/\n",
    "\n",
    " #### &bull; **Frontend: Gradio**\n",
    "\n",
    " https://www.gradio.app/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
